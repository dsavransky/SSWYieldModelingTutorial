{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add1c8e0-e4d9-41bf-80a8-ae1884ae397e",
   "metadata": {},
   "source": [
    "This notebook includes markdown cells (such as this one), which provide useful information and narration of what is happening, and code cells (such as the next one), which actually do things. To execute a code cells, click in the cell and then hit Shift+Enter. Alternatively, click within a cell and hit the Run button (play symbol). When a cell completes executing, a number will appear (or update) on the left-hand side of the cell. You can also execute some or all of the cells via options in the 'Runtime' menu, above.  \n",
    "\n",
    "**Important**: Note that some of the code blocks include exercises, with incomplete code, so you can't just run the whole notebook. You are strongly encouraged to go through the blocks one by one, in the order given.  Exercises do not need to be fully completed before proceeding to the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512881-f69b-4b5e-a60d-b944374e2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the tutorial repository - this can take a little while\n",
    "!git clone --depth 1 https://github.com/dsavransky/SSWYieldModelingTutorial\n",
    "# change into the repo dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90cc45-2bfb-4f24-9c3d-5124dc55e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd SSWYieldModelingTutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdb971-9239-461f-a485-b0d34871727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the tutorial backend and requirements - this can also take a little while\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf2f58-23a9-4477-8644-b83234b62816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required modules\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from sympy import symbols, cos, sin, Matrix, simplify, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "from matplotlib import ticker\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f8d0d-c57e-458e-b3e2-f983860af47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is temporary debugging code and will be removed\n",
    "import importlib\n",
    "import SSWYieldModelingTutorial.SSWYieldModelingTutorial\n",
    "importlib.reload(SSWYieldModelingTutorial.SSWYieldModelingTutorial)\n",
    "from SSWYieldModelingTutorial import SSWYieldModelingTutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc93ca-0b34-41e5-828d-6b40f7eb8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up plotting\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "%matplotlib widget\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d2896-2d2d-4caf-bc64-836dc35d8f6b",
   "metadata": {},
   "source": [
    "# The Direct Imaging Observables\n",
    "\n",
    "## Derivation of the Governing Equations\n",
    "We wish to compute the direct imaging observable parameters over the course of a planet's orbit.  Typically, we parametrize these observables as the projected separation between star and planet ($s$) and the difference in brightness between planet and star (their flux ratio on a magnitude scale, which we call $\\Delta\\mathrm{mag}$. \n",
    "\n",
    "A two-body (Keplerian) orbit is typically encoded via 6 variables: The semi-major axis ($a$) and eccentricity ($e$) which define the shape of the conic section of the orbit (in our case, all orbits will be elliptical or circular). The orbit's orientation in 3-dimensional space is encoded via three Euler angles: the argument of periapsis ($\\omega$), the inclination ($I$), and the longitude of the ascending node ($\\Omega$). Finally, in order to map time on the orbit to absolute time, we need to define the time of periapsis passage (closest approach between the planet and its host star: $t_p$). The planet's progress along its orbit can then be tracked via time, or any one of several anomaly angles, such as the true anomaly ($\\nu$). From these parameters, we can define the planet's orbital radius magnitude as:\n",
    "$$r = \\frac{a(1 - e^2)}{1 + e\\cos(\\nu)}$$\n",
    "\n",
    "![title](../img/exoplanet_orbit_diagram_annotated.png)\n",
    "\n",
    "Let's get Python to produce equations for these starting from first principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17a72b-5d4b-4464-ab86-f623f626bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define required symbols and the rotation matrices for the orbit's rotation\n",
    "r,I,O,w,nu,th = symbols(\"r,I,Omega,omega,nu,theta\",real=True, positive=True)\n",
    "rot1 = Matrix(([cos(O), sin(O), 0], [-sin(O), cos(O), 0], [0, 0, 1]))\n",
    "rot2 = Matrix(([1, 0, 0], [0, cos(I), sin(I)], [0, -sin(I), cos(I)]))\n",
    "rot3 = Matrix(([cos(w), sin(w), 0], [-sin(w), cos(w), 0], [0, 0, 1]))\n",
    "pCi = rot3*rot2*rot1 # this is the rotation of the perifocal frame in the inertial frame\n",
    "iCp = pCi.transpose() # this is the rotation of the inertial frame in the perifocal frame\n",
    "\n",
    "# we can now define the orbital radius vector in the frame where the observer\n",
    "# is located along the negative third axis\n",
    "r_p = Matrix([r*cos(nu),r*sin(nu),0])\n",
    "r_i = simplify(iCp*r_p)\n",
    "r_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154cc51-7b6e-4695-be22-7db085f2d2da",
   "metadata": {},
   "source": [
    "We can simplify things a bit by defining the argument of latitude $\\theta \\triangleq \\nu+\\omega$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ec4f4-84a3-4574-825c-ab9acf7a7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_i = r_i.subs(nu+w, th)\n",
    "r_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980fa42-6f30-428a-88fc-a8e9df8b9cb9",
   "metadata": {},
   "source": [
    "We can now find an expression for the projected separation from the first two components of our orbital radius vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e255f-d6fb-4be3-8265-8c6d4add0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = simplify(sqrt(r_i[0]**2 + r_i[1]**2))\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1d74d-97b8-4c8c-8e97-cec940a4662d",
   "metadata": {},
   "source": [
    "The $\\Delta\\mathrm{mag}$ is a bit more complicated: \n",
    "$$ \\Delta{\\textrm{mag}} \\triangleq -2.5\\log_{10}\\left(\\frac{F_P}{F_S}\\right) =  -2.5\\log_{10}\\left(p\\Phi(\\beta) \\left(\\frac{R_P}{r}\\right)^2 \\right)$$\n",
    "where $p$ is the geometric albedo of the planet (the fraction of light reflected/scattered by the planet), $R_P$ is the planet's radius, and $Phi(\\beta)$ is the planet's phase function (how the fraction of reflected light changes with the planet's phase angle $\\beta$).  The phase angle is the star-planet-observer angle, and can be approximated as:\n",
    "$$ \\cos\\beta \\approx \\sin I \\sin\\theta$$\n",
    "\n",
    "Note that we can calculate both $s$ and $\\Delta\\mathrm{mag}$ with only a subset of our orbital elements and planetary parameters.  All that we need is $a, e, \\nu, \\omega, I, R_P$.\n",
    "\n",
    "Real planets can have very complex phase functions, based on many parameters whose distributions are not yet well known.  Instead of modeling all of this complexity, we frequently just use the Lambert phase function, which describes an isotropic scatterer (one that reflects light equally in all directions):\n",
    "\n",
    "$$\\pi\\Phi_L(\\beta) = \\sin\\beta + (\\pi - \\beta)\\cos\\beta$$\n",
    "\n",
    "Let's now simulate the observable values over the course of one orbit. We'll define some parameters that are vaguely Earth-like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcc3b2-314b-467c-8dc2-ed8a3412551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the orbital elements. Note the use of astropy units to keep things consistent\n",
    "a = 1*u.AU #semi-major axis = 1 AU\n",
    "e = 0.2 # this is actually a pretty high eccentricity\n",
    "I = 90*u.deg # 90 degree inclination - edge-on orbit\n",
    "w = 15*u.deg # 15 degree argument of periapsis\n",
    "R_P = 1*u.earthRad # Earth radius-equivalent planet\n",
    "p = 0.367 # geometric albedo\n",
    "nu = np.linspace(0,2*np.pi,100)*u.rad # The true anomaly varies between 0 and 2\\pi over the course of the orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b029f-9341-4f6e-8ea6-7de0afc324dc",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Now it's your turn.  Write code to use the variables defined in the previous block to compute the projected separation and $\\Delta\\mathrm{mag}$ over the course of the orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77988ad0-66a9-440a-b4e0-9de70e312bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the observables\n",
    "# Note that these are numerical computations on arrays, so you should be using numpy\n",
    "# methods, such as np.cos, np.sin, np.sqrt, etc.\n",
    "r =       # compute the oribtal radius\n",
    "theta =   # compute the argument of latitude\n",
    "s =       # compute the projected separation\n",
    "beta =    # compute the phase angle\n",
    "Phi =     # compute the value of the Lambert phase function\n",
    "dMag =    # compute the Delta mag\n",
    "\n",
    "# if you get stuck, a reference solution is provided by:\n",
    "# s, dMag = SSWYieldModelingTutorial.calc_s_dMag(a, e, I, w, R_P, p, nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91043ec6-66b5-484e-89ed-b98729870ad0",
   "metadata": {},
   "source": [
    "Now that we have some values, let's plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7643a-c919-404a-be79-e944876815c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some values \n",
    "fig1, ax1a = plt.subplots()\n",
    "\n",
    "color1 = 'tab:red'\n",
    "ax1a.set_xlabel(f'True Anomaly ({nu.unit})')\n",
    "ax1a.set_ylabel(f'Projected Separation ({s.unit})', color=color1)\n",
    "ax1a.plot(nu, s, color=color1)\n",
    "ax1a.tick_params(axis='y', labelcolor=color1)\n",
    "ax1a.set_xlim([0,2*np.pi])\n",
    "\n",
    "ax1b = ax1a.twinx() \n",
    "color2 = 'tab:blue'\n",
    "ax1b.set_ylabel('$\\Delta$mag', color=color2) \n",
    "ax1b.plot(nu, dMag, color=color2)\n",
    "ax1b.tick_params(axis='y', labelcolor=color2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc41542-9809-4cf5-a249-656d25f09b0a",
   "metadata": {},
   "source": [
    "Remember: the point of computing these values is to check whether or not a planet is visible at a given time.  The simplest way to do so is to define limits on observable projected separations and $\\Delta\\mathrm{mag}$ values.  For projected separation, this actually maps quite well to how starlight-suppression systems work.  Essentially all such systems have an inner working angle (IWA) and outer working angle (OWA).  If expressed in units of arcseconds, these values map directly to minimum and maximum observable projected separations (in AU) when multiplied by the distance to the target (in parsecs).  For $\\Delta\\mathrm{mag}$, as we will presently see, setting limits is a bit more complicated, so for now, we will just say that we can pick a constant $\\Delta\\mathrm{mag}$ limit. \n",
    "\n",
    "Let's define some limits and see how these limits interact with our plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37985cd-7771-4930-a635-c5cad3c52df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IWA = 0.075 #arcseconds\n",
    "OWA = 2 #arcseconds\n",
    "d = 10  #distane to star in parsecs\n",
    "dMaglim = 25 #we have a constant limiting delta magnitude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c77e5-8e04-4842-b93a-a2f19d973a6d",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Using the previously computed values of $s$ and $\\Delta\\mathrm{mag}$, along with the limits defined in the previous block, compute a boolean array of values (of the same size as `s` and `dMag`) that is True where the planet is observable and false otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1923f-f46f-48ae-a862-992a8affc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are being asked to compute boolean values on an array, which can be done\n",
    "# with comparison operators such as >, >=, ==, etc.  Arrays of boolean values\n",
    "# can also be ANDed or ORed as (bool arr 1) & (bool arr 2) and \n",
    "# (bool arr 1) | (bool arr 2), respectively\n",
    "\n",
    "observable_indices =\n",
    "\n",
    "# if you get stuck, a reference solution is provided by:\n",
    "# observable_indices = SSWYieldModelingTutorial.observable_indices(s, dMag, d, IWA, OWA, dMaglim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc1222-59d9-479d-bd74-d8cdd73b214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's update our plot with the observable regions highlighted\n",
    "# the planet is obserable under our stated constraints (dashed lines)\n",
    "# on the thicker portions of the plots\n",
    "\n",
    "# this is just used to split the observable indices into contiguous blocks for plotting:\n",
    "sepinds = SSWYieldModelingTutorial.split_observable_inds(observable_indices)\n",
    "\n",
    "for inds in sepinds:\n",
    "    ax1a.plot(nu[inds], s[inds],color=color1, linewidth=4)\n",
    "ax1a.plot([0,2*np.pi], [IWA*d]*2, '--', color=color1)\n",
    "\n",
    "for inds in sepinds:\n",
    "    ax1b.plot(nu[inds], dMag[inds],color=color2, linewidth=4)\n",
    "ax1b.plot([0,2*np.pi], [dMaglim]*2, '--', color=color2)\n",
    "\n",
    "# scroll up to see the updates on your original plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cfdde8-9fff-4dcd-bf42-ccfb882a1656",
   "metadata": {},
   "source": [
    "## The Impact of Orbital Inclination\n",
    "\n",
    "Of all of the input parameters, the one that has the largest impact on these values is the inclination (why?).  Let's see how the curves change as we change the orbital inclination. Note that this is also a chance to check your results from the first two exercises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbc150-3322-4295-8fd8-198ec675a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to now compute s and dMag on a grid of I and nu values\n",
    "I0 = np.linspace(0,np.pi,101)*u.rad # full range of possible integrations\n",
    "nu0 = np.linspace(0,2*np.pi,100)*u.rad # The true anomaly varies between 0 and 2\\pi over the course of the orbit\n",
    "[Is, nus] = np.meshgrid(I0,nu0)\n",
    "\n",
    "ss, dMags = SSWYieldModelingTutorial.calc_s_dMag(1*u.AU, 0.2, Is, 15*u.deg,  1*u.earthRad, 0.367, nus)\n",
    "ss = ss.transpose()\n",
    "dMags = dMags.transpose()\n",
    "\n",
    "# same constraints as before:\n",
    "IWA = 0.075 #arcseconds\n",
    "OWA = 2 #arcseconds\n",
    "d = 10  #distane to star in parsecs\n",
    "dMaglim = 25 #we have a constant limiting delta magnitude \n",
    "\n",
    "fig2, ax2a = plt.subplots()\n",
    "\n",
    "color1 = 'tab:red'\n",
    "ax2a.set_xlabel(f'True Anomaly ({nu0.unit})')\n",
    "ax2a.set_ylabel(f'Projected Separation ({ss.unit})', color=color1)\n",
    "scurve = ax2a.plot(nu0, ss[0], color=color1)[0]\n",
    "ax2a.tick_params(axis='y', labelcolor=color1)\n",
    "ax2a.set_xlim([0,2*np.pi])\n",
    "ax2a.plot([0,2*np.pi], [IWA*d]*2, '--', color=color1)\n",
    "\n",
    "ax2b = ax2a.twinx() \n",
    "color2 = 'tab:blue'\n",
    "ax2b.set_ylabel('$\\Delta$mag', color=color2) \n",
    "dMagcurve = ax2b.plot(nu0, dMags[0], color=color2)[0]\n",
    "ax2b.tick_params(axis='y', labelcolor=color2)\n",
    "ax2b.plot([0,2*np.pi], [dMaglim]*2, '--', color=color2)\n",
    "\n",
    "fig2.suptitle(f\"I = {I0[0].to(u.deg) :.2f}\")\n",
    "overlines = []\n",
    "\n",
    "def drawInclinationFrame(j):\n",
    "    scurve.set_data(nu0, ss[j])\n",
    "    dMagcurve.set_data(nu0, dMags[j])\n",
    "    fig2.suptitle(f\"I = {I0[j].to(u.deg):.2f}\")\n",
    "    ax2a.set_ylim([ss[j].value.min(), ss[j].value.max()])\n",
    "    ax2b.set_ylim([dMags[j].min(), dMags[j].max()])\n",
    "    obsinds = SSWYieldModelingTutorial.observable_indices(ss[j], dMags[j], d, IWA, OWA, dMaglim)\n",
    "    sepinds = SSWYieldModelingTutorial.split_observable_inds(obsinds)\n",
    "    while len(overlines) > 0:\n",
    "        overlines.pop().remove()\n",
    "    for inds in sepinds:\n",
    "        overlines.append(ax2a.plot(nu0[inds], ss[j][inds],color=color1, linewidth=4)[0])\n",
    "    for inds in sepinds:\n",
    "        overlines.append(ax2b.plot(nu0[inds], dMags[j][inds],color=color2, linewidth=4)[0])\n",
    "\n",
    "widgets.interact(drawInclinationFrame, j=widgets.IntSlider(min=0, max=len(I0)-1, step=1, value=50));\n",
    "# use slider to change the orbit inclination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149095ac-c0d1-44d2-9ae9-af7bf3cfd2f5",
   "metadata": {},
   "source": [
    "A key aspect of what we're seeing here is that orbital inclination places a limit on the range of observable face angle.  A face-on orbit (one with a 0$^\\circ$ inclination) will always be viewed at a 90$^\\circ$ phase (known as **quadrature**). Only an edge-on orbit (one with 90$^\\circ$) inclination will actually pass through the full range of $\\beta$ values (0 to 180$^\\circ$).  For intermediate values of inclination, the planet phase will always be in the range $[90^\\circ - I, 90^\\circ + I]$.\n",
    "\n",
    "Another very important thing to note is the range of projected separations.  If you look back to the orbital radius magnitude equation, you'll note that the orbital radius ranges between $a(1-e)$ and $a(1+e)$.  The projected separation will always be less than or equal to the orbital radius (we can see this by inspection of the equation we derived, above). This means that when the projected separation is smaller than the semi-major axis, this is due to either the orbital eccentricity or projection effects (e.g., when the orbit is anything other than face-on).  When the projected separation is greater than the semi-major axis, this is due *only* to eccentricity.  A cool result that you can prove from all of this is that, given a single observation of a planet, the observed projected separation is actually the maximum likelihood estimate of its semi-major axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b58251-fa76-4310-914f-bb7d1dc76ffc",
   "metadata": {},
   "source": [
    "# The Direct Imaging Observable Joint Probability Density Function\n",
    "\n",
    "Now that we have the ability to compute the imaging observables, we can proceed to compute the joint probability density function of these values for a given population of planets. We will call this density function $f_{\\Delta\\mathrm{mag},s}$.\n",
    "\n",
    "There are multiple different ways to do this calculation, but the conceptually simplest is via Monte Carlo: we will draw random samples from density functions describing all of our input parameters, and then use these to compute the corresponding projected separation and $\\Delta\\mathrm{mag}$ values.  We will then form a 2D histogram over these computed values, thereby estimating their joint probability density function.\n",
    "\n",
    "An important thing to note is that, in reality, the input parameters may not be independent, and may have joint prior functions of their own.  Here, we will ignore this bit of complexity, and treat all inputs as fully independent of one another. \n",
    "\n",
    "We are going to try modeling a population of Earth-like planets.  Note that there is an enormous body of literature establishing various priors for this population. Here, we will make multiple simplifying assumptions.\n",
    "\n",
    "For the semi-major axis, we will assume a uniform distribution between 0.7 and 1.5 AU (note that this assumption is non-physical - real planet orbits appear to be distributed logarithmically in semi-major axis, but this is a reasonable approximation to make when focusing on a small interval of semi-major axes. We will similarly approximate eccentricities as uniformly distributed between 0 and 0.35 (again, this is not what the actual universe appears to do). We will take all of the planets in our population to have radii of exactly 1 Earth radius, and geometric albedos of 0.367. \n",
    "\n",
    "Finally, we will assume that orbit orientation are isotropically distributed over the unit sphere (e.g., that there is no preferred orbital plane).  This means that both $\\omega$ and $\\Omega$ are uniformly distributed between 0 and $2\\pi$ radians, whereas $I$ is sinusoidally distributed, e.g.:\n",
    "$$f_\\bar{I}(I) = \\begin{cases} \\dfrac{\\sin(I)}{2}  & I \\in [0, \\pi] \\\\ 0 & \\mathrm{else} \\end{cases}$$\n",
    "\n",
    "Finally, we are interested in sampling the populations consistently with arbitrarily timed observations.  Thus, we treat the time of observation as uniformly distributed, which corresponds to a uniform distribution in mean anomaly ($M$). This is related to the true anomaly via the Kepler time equation:\n",
    "$$M = E - e\\sin(E)$$\n",
    "where $E$ is the eccentric anomaly, which maps to true anomaly as:\n",
    "$$\\tan\\left(\\frac{E}{2}\\right) = \\sqrt{\\frac{1-e}{1+e}}\\tan\\left(\\frac{\\nu}{2}\\right)$$\n",
    "\n",
    "## Exercise 3\n",
    "Let's generate some values and see how this all works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b672a58-3621-45f0-8aa2-36e763eef606",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(1e5); #number of samples to generate\n",
    "# these values are constant\n",
    "R_P = (1*u.earthRad).to(u.AU).value # Earth radius-equivalent planet in AU\n",
    "p = 0.367 # geometric albedo\n",
    "\n",
    "# we'll skip the units this time to make computations a bit more efficient\n",
    "# Hint 1: numpy provides the very useful method np.random.uniform. See:\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
    "#\n",
    "# Hint 2: A sinusoidal distribution can be generated by taking the \n",
    "#         arccosine of a uniform distribution between -1 and 1\n",
    "\n",
    "# generate an array of semi-major axis values\n",
    "# uniformly distributed between 0.7 and 1.5 AU:\n",
    "avals = \n",
    "\n",
    "# generate an array of eccentricity values\n",
    "# uniformly distributed between 0 and 0.35\n",
    "evals = \n",
    "\n",
    "# generate an array of argument of periapsis values\n",
    "# uniformly distributed between 0 and 2\\pi\n",
    "wvals = \n",
    "\n",
    "# generate an array of inclination values \n",
    "# sinusoidally distributed between 0 and \\pi\n",
    "Ivals = \n",
    "\n",
    "# Generate an array of mean anomaly values \n",
    "# uinformly distributed between 0 and 2\\pi\n",
    "Mvals = \n",
    "\n",
    "# if you get stuck, a reference solution is provided by:\n",
    "#avals, evals, wvals, Ivals, Mvals, R_P, p = SSWYieldModelingTutorial.gen_Earthlike_values(int(1e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454fdc12-7159-49ed-95ae-48b30a995ad9",
   "metadata": {},
   "source": [
    "Now that we have the values, we need a bit more work before we can compute our imaging observables.  In particular, note that the Kepler time equation is a transcendental function, and must be inverted numerically (typically using Newton-Raphson iteration). There are many, many software packages in the Python ecosystem that will do this for you - we will use our own implementation here, but lots of others are available to you.\n",
    "\n",
    "Once we have the true anomaly values, we can use our previously written code to compute the corresponding projected separation and $\\Delta\\mathrm{mag}$ values.  We then use some helper method to compute the 2D histogram of these values (normalized by the number of samples and bin areas to make it representative of a true probability density function) and finally to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f7025-4283-47a7-86ec-1b753c10c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute true anomaly from mean anomaly and eccentricity\n",
    "_,_,nuvals = SSWYieldModelingTutorial.invKepler(Mvals, evals, return_nu=True)\n",
    "\n",
    "\n",
    "# set semi-major axis and eccentricity ranges:\n",
    "arange, erange = [0.7, 1.5], [0, 0.35]\n",
    "\n",
    "# compute the imaging observables\n",
    "svals, dMagvals = SSWYieldModelingTutorial.calc_s_dMag(avals, evals, Ivals, wvals,  R_P, p, nuvals)\n",
    "\n",
    "# generate the 2D histogram of the values\n",
    "Cpdf, sax, dMagax = SSWYieldModelingTutorial.gen_Cpdf(1000, dMagvals, svals, arange, erange, p, R_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0365e9-0e9a-446e-82fe-89b8333f4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cs = ax3.contourf(\n",
    "        sax,\n",
    "        dMagax,\n",
    "        Cpdf,\n",
    "        locator=ticker.LogLocator(),\n",
    "    )\n",
    "ax3.set_xlabel(\"Projected Separation (AU)\")\n",
    "ax3.set_ylabel(\"$\\Delta$mag\");\n",
    "cbar = fig3.colorbar(cs)\n",
    "cbar.ax.set_title(\"$f_{\\Delta\\\\mathrm{mag},s}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66906281-814b-4143-aa28-0d18b0040a9c",
   "metadata": {},
   "source": [
    "This plot looks a bit sparse, but its hard to tell.  Wouldn't it be great if we could compute the bounds of this density function?  Turns out that, while computing the distribution itself analytically is non-trivial (although possible), it is relatively straightforward to establish upper and lower bounds on $\\Delta\\mathrm{mag}$ as a function of $s$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5359df-56fe-4cf0-98f5-4685e41aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmagmax, dmagmin, dmag90 = SSWYieldModelingTutorial.calc_Cpdf_limits(sax, arange, erange, p, R_P)\n",
    "ax3.plot(sax, dmagmax, \"r\", linewidth=4, label=\"$\\\\Delta\\\\mathrm{mag}_\\\\mathrm{max}$\")\n",
    "ax3.plot(sax, dmagmin, \"b\", linewidth=4, label=\"$\\\\Delta\\\\mathrm{mag}_\\\\mathrm{min}$\")\n",
    "ax3.plot(sax, dmag90, \"k--\", label=\"$\\\\beta = 90^\\\\circ$\")\n",
    "ax3.legend()\n",
    "ax3.set_ylim([20,40]);\n",
    "# check back to your original plot for the limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13cbbd7-754c-4bec-97a4-230bcdea6f48",
   "metadata": {},
   "source": [
    "## Fully Sampling the Joint Probability Density Function\n",
    "\n",
    "Clearly, we are failing to completely fill the space with our sampling.  This is one of the drawbacks of any Monte Carlo approach, and is related to the so-called 'curse of dimensionality': the larger the number of dimensions in your system, the more samples you need to fully sample the phase space, quickly leading to an infeasible required number of samples.  On thing helps us in this particular case: if you look carefully, you'll note that the highest probability portion of the space lies along the minimum $\\Delta\\mathrm{mag}$ curve. This means that as we add more samples, we'll automatically fill in the most interesting (to us) part of the phase space first. However, the $10^5$ samples we generated here are clearly inadequate.  Typically, we will draw at least $10^8$ samples for this distribution.  This takes a while, so we've precalculated them for you (and actually gone a bit overboard and generated a full billion samples).  Here's what a better sampled version of this density function looks like (and this is a chance to check your work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68c43e-95f4-4b1c-bada-1845a7e4f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set semi-major axis and eccentricity ranges:\n",
    "arange, erange = [0.7, 1.5], [0, 0.35]\n",
    "R_P = (1*u.earthRad).to(u.AU).value # Earth radius-equivalent planet in AU\n",
    "p = 0.367 # geometric albedo\n",
    "Cpdf, sax, dMagax = SSWYieldModelingTutorial.load_precomputed_completeness()\n",
    "dmagmax, dmagmin, dmag90 = SSWYieldModelingTutorial.calc_Cpdf_limits(sax, arange, erange, p, R_P)\n",
    "fig4, ax4 = plt.subplots()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cs = ax4.contourf(\n",
    "        sax,\n",
    "        dMagax,\n",
    "        Cpdf,\n",
    "        locator=ticker.LogLocator(),\n",
    "    )\n",
    "ax4.set_xlabel(\"Projected Separation (AU)\")\n",
    "ax4.set_ylabel(\"$\\Delta$mag\");\n",
    "cbar = fig4.colorbar(cs)\n",
    "cbar.ax.set_title(\"$f_{\\Delta\\\\mathrm{mag},s}$\");\n",
    "ax4.plot(sax, dmagmax, \"r\", linewidth=4, label=\"$\\\\Delta\\\\mathrm{mag}_\\\\mathrm{max}$\")\n",
    "ax4.plot(sax, dmagmin, \"b\", linewidth=4, label=\"$\\\\Delta\\\\mathrm{mag}_\\\\mathrm{min}$\")\n",
    "ax4.plot(sax, dmag90, \"k--\", label=\"$\\\\beta = 90^\\\\circ$\")\n",
    "ax4.legend()\n",
    "ax4.set_ylim([20,45]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7fa20a-f7bc-4fa1-99b1-54c32752d460",
   "metadata": {},
   "source": [
    "We immediately see that with a full $10^9$ samples, we fully fill the space between our maximum and minimum bounding lines.  More importantly, there are no samples outside of these lines, proving that the bounds are correctly computed. Take a moment to study this plot.  This is often referred to as a 'bird plot' (after the shape), and was first published by Bob Brown in his 2005 paper (possibly the most important contribution to the field of exoplanet yield modeling).  The shape of the joint density function is entirely driven by the input parameters.  The divot on the left-hand side of the plot is due to our inclusion of a maximum eccentricity value (allowing eccentricities up to the upper bound of 1 would fill in the blank area present in the current plot).  Finally, we can confirm what we suspected from our previous iteration of this plot: the highest probability region of this density function lies along the bounding minimum $\\Delta\\mathrm{mag}$ curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e3564-34a1-4175-bda7-2252ca42f6fd",
   "metadata": {},
   "source": [
    "# Completeness\n",
    "\n",
    "We now have all of the building blocks we need in order to compute **completeness**: the probability of detecting a planet from a given population about a given target star with a given instrument, assuming that one is there.  Obviously, this is a whole lot of 'givens', but we've actually already established all of them.  Our assumed population of planets is fully encoded in the joint probability density function we evaluated in the previous section.  The instrument is encoded by the inner and outer working angles and the limiting $\\Delta\\mathrm{mag}$. Putting these two together, the completeness is then just the marginalization of the joint density function under the instrumental constraints:\n",
    "$$ c = \\int_{s_\\textrm{min}}^{s_\\textrm{max}} \\int_0^{\\Delta\\mathrm{mag}_\\mathrm{lim}} f_{\\Delta\\mathrm{mag},s} \\, \\mathrm{d}\\Delta\\mathrm{mag}\\,\\mathrm{d}s$$\n",
    "where $s_\\textrm{min},s_\\textrm{max}$ are the minimum and maximum observable projected separation values, which, as previously discussed can be computed as IWA$d$ and OWA$d$, respectively, where $d$ is the distance to the target star in parsecs.\n",
    "\n",
    "As we have computed our joint observable distribution as a discretized, normalized 2D histogram, we can implement the double integral in the equation above as a double summation (this is equivalent to implementing a Riemann sum):\n",
    "$$ c \\approx \\sum_{s = s_\\textrm{min}}^{s_\\textrm{max}} \\sum_{\\Delta\\mathrm{mag} = 0}^{\\Delta\\mathrm{mag}_\\mathrm{lim}} C_\\mathrm{pdf}(s, \\Delta\\mathrm{mag})$$\n",
    "\n",
    "Essentially, we are carving out a rectangular area within our joint density function (under the assumption that the limiting $\\Delta\\mathrm{mag}$ is constant at all projected separations), and then summing the contents of our histogram within this box.  This looks something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ee97f-6433-4949-ab21-0fd6ec4cd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cs = ax4.contourf(\n",
    "        sax,\n",
    "        dMagax,\n",
    "        Cpdf,\n",
    "        locator=ticker.LogLocator(),\n",
    "    )\n",
    "ax4.set_xlabel(\"Projected Separation (AU)\")\n",
    "ax4.set_ylabel(\"$\\Delta$mag\");\n",
    "cbar = fig4.colorbar(cs)\n",
    "cbar.ax.set_title(\"$f_{\\Delta\\\\mathrm{mag},s}$\");\n",
    "ylim = [20,45]\n",
    "ax4.set_ylim(ylim);\n",
    "projIWA = 0.075 # AU\n",
    "projOWA = 1 # AU\n",
    "ax4.plot([projIWA] * 2, [ylim[0], 25], \"k--\", label=\"Projected IWA\")\n",
    "ax4.plot([projOWA] * 2, [ylim[0], 25], \"k-.\", label=\"Projected OWA\")\n",
    "ax4.plot([projIWA, projOWA], [25] * 2, \"k:\", label=\"$\\\\Delta$mag=25\")\n",
    "ax4.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf73f0-bfff-471b-86cb-949a74c2dfc1",
   "metadata": {},
   "source": [
    "One caveat here is that the grid that we computed the histogram over may be discretized too coarsely (that is, we may wish to pick limits that fall between grid entries).  We solve this by interpolating over the grid.\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "Let's try this out.  Write a function that, given the joint observable PDF and instrument limits, computes the completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d5951-67d0-4432-a3ae-20e59457396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_completeness(Cpdf, sax, dMagax, smin, smax, dMaglim):\n",
    "    \"\"\"Compute the completeness of an observation\n",
    "\n",
    "    Args:\n",
    "        Cpdf (np.ndarray):\n",
    "            2D, normalized, joint probability histogram of s and dMag\n",
    "        sax (np.ndarray):\n",
    "            Projected separation axis of Cpdf (AU)\n",
    "        dMagax (np.ndarray):\n",
    "            dMag axis of Cpdf\n",
    "        smin (arraylike):\n",
    "            Minimum observable projected separation (projected IWA) (AU)\n",
    "        smax (arraylike):\n",
    "            Maximum observable projected separation (projected OWA) (AU)\n",
    "        dMaglim (arraylike):\n",
    "            Maximum observable Delta mag value\n",
    "\n",
    "    Returns:\n",
    "        arraylike:\n",
    "            Completeness values\n",
    "            \n",
    "    Notes:\n",
    "        All arraylike inputs must have the same dimensionalities (or be scalars)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Your code goes here\n",
    "    # Hint 1: You may find the method scipy.interpolate.RectBivariateSpline useful here. See:\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.RectBivariateSpline.html\n",
    "    #\n",
    "    # Hint 2: The contents of Cpdf are probably transposed from what you might expect\n",
    "    \n",
    "    comp = \n",
    "    \n",
    "    return comp\n",
    "\n",
    "# if you get stuck: a reference implementation is available in SSWYieldModelingTutorial.calc_completeness\n",
    "\n",
    "# when you're done, test your function:\n",
    "calc_completeness(Cpdf, sax, dMagax, 0.075, 1, 25)\n",
    "# the expected output is ~0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade7aa7-ce97-4655-bad7-2c48058bab2a",
   "metadata": {},
   "source": [
    "## The Impact of Stellar Distance\n",
    "Now that we have the capability to compute completeness values, we can explore how they change with inputs.  We've already established that the minimum and maximum observable projected separations are linear functions of stellar distance.  Let's look at how the target star's distance impacts the completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da10b55-f6cb-4003-bf0c-faeadb37a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll consider targets in the range of 1 to 41 parsecs\n",
    "dists = np.arange(1, 41) # parsecs\n",
    "IWA = 0.05 # arcseconds\n",
    "OWA = 0.25 # arcseconds\n",
    "smins = IWA*dists\n",
    "smaxs = OWA*dists\n",
    "dMaglim = 25\n",
    "comps = SSWYieldModelingTutorial.calc_completeness(Cpdf, sax, dMagax, smins, smaxs, dMaglim)\n",
    "\n",
    "ylim = [20,45]\n",
    "fig5, axs5 = plt.subplots(1, 2)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cs = axs5[0].contourf(\n",
    "        sax,\n",
    "        dMagax,\n",
    "        Cpdf,\n",
    "        locator=ticker.LogLocator(),\n",
    "    )\n",
    "axs5[0].set_xlabel(\"Projected Separation (AU)\")\n",
    "axs5[0].set_ylabel(\"$\\Delta$mag\")\n",
    "pIWA = axs5[0].plot([smins[0]] * 2, [ylim[0], dMaglim], \"k--\", label=\"Projected IWA\")[0]\n",
    "pOWA = axs5[0].plot([smaxs[0]] * 2, [ylim[0], dMaglim], \"k-.\", label=\"Projected OWA\")[0]\n",
    "dmaglim = axs5[0].plot(\n",
    "    [smins[0], smaxs[0]], [25] * 2, \"k:\", label=f\"$\\\\Delta$mag={dMaglim}\"\n",
    ")[0]\n",
    "axs5[0].legend()\n",
    "axs5[0].set_ylim(ylim)\n",
    "xlim0 = axs5[0].get_xlim()\n",
    "fig5.suptitle(f\"$d = ${dists[0]}\")\n",
    "\n",
    "compline = axs5[1].plot(dists[0], comps[0])[0]\n",
    "comppoint = axs5[1].scatter(dists[0], comps[0])\n",
    "axs5[1].set_xlim([0, 40])\n",
    "axs5[1].set_ylim([0, 1])\n",
    "axs5[1].set_xlabel(\"Star Distance (pc)\")\n",
    "axs5[1].set_ylabel(\"Completeness\")\n",
    "\n",
    "plt.subplots_adjust(top=0.925, left=0.075, right=0.975)\n",
    "\n",
    "def drawCompFrame(j):\n",
    "    pIWA.set_data([smins[j]] * 2, [ylim[0], 26])\n",
    "    pOWA.set_data([smaxs[j]] * 2, [ylim[0], 26])\n",
    "    dmaglim.set_data([smins[j], smaxs[j]], [26] * 2)\n",
    "    if smaxs[j] > sax.max():\n",
    "        axs5[0].set_xlim([0, smaxs[j]])\n",
    "    else:\n",
    "        axs5[0].set_xlim(xlim0)\n",
    "    fig5.suptitle(f\"$d = ${dists[j]}\")\n",
    "    compline.set_data(dists[: j + 1], comps[: j + 1])\n",
    "    comppoint.set_offsets((dists[j], comps[j]))\n",
    "    \n",
    "widgets.interact(drawCompFrame, j=widgets.IntSlider(min=0, max=len(dists)-1, step=1, value=0));\n",
    "# use slider to change the star distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9ba6a-222c-4e0e-93b0-f384d520a01f",
   "metadata": {},
   "source": [
    "We can see that the effect of moving to further and further targets: the observable box scales linearly outwards from the star, covering a different subsection of the joint density function for different stellar distances.  For the specific IWA/OWA values we have selected here, the bounding box covers the largest portion of the highest-probability portion of the distribution for a stellar distance of ~7 pc, leading to the highest completeness value at that distance.  \n",
    "\n",
    "**Be very careful here**.  Note *all* of the assumptions that went into this result.  We had to both postulate the underlying planet population *and* the instrument's capabilities. Making changes to either would lead to a different result.\n",
    "\n",
    "The second thing to note is that we only needed to compute the underlying density function once.  In order to get different completeness results for different observing cases, we only adjusted the limits of our integration (summation).  This will be a recurring theme as we study other effects.\n",
    "\n",
    "## Habitable Zones and Stellar Luminosity\n",
    "\n",
    "At first glance, our equations do not predict any changes in completeness with stellar luminosity, but this changes when you focus specifically on Earth-like planets.  While there is not broad consensus on what exactly makes a planet 'Earth-like', in general, you want these planets to receive about as much radiant flux from their host stars as the Earth receives from the sun. This means that we wish to match insolation distance rather than absolute distance between planet and star. That is, we want to scale our planets' semi-major axes as $a = \\sqrt{L}a_{L=1 L_\\odot}$ where $a_{L=1 L_\\odot}$ is the semi-major axis at 1 solar luminosity. The full range of semi-major axes we wish to study is similarly scaled, leading to a very basic definition of the **habitable zone**. \n",
    "\n",
    "This semi-major axis scaling implies that the orbital radius similarly scales as $r = \\sqrt{L}r_{L=1 L_\\odot}$, meaning that so does the projected separation: $$s = \\sqrt{L}s_{L=1 L_\\odot}$$\n",
    "\n",
    "If you plug these scalings into the $\\Delta\\mathrm{mag}$ expression, you find:\n",
    "$$\\Delta\\mathrm{mag} = \\Delta\\mathrm{mag}_{L=1 L_\\odot} + 2.5\\log_{10}\\left(L\\right)$$\n",
    "\n",
    "Note that there's no need to recompute our underlying joint probability density function for different values of stellar luminosity.  Instead, we only need to re-interpret the axes.  With the inclusion of stellar luminosity, we read the abscissa as $s/\\sqrt{L}$ and the ordinate as $\\Delta\\mathrm{mag} - 2.5\\log_{10}\\left(L\\right)$.\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "Let's try this out. Update your previous completeness calculation function, taking into account the stellar luminosity (under the assumption that we're matching stellar insolation for our planet population). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ed5f3-9f4b-4ef4-9852-ba24f59a26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_completeness(Cpdf, sax, dMagax, smin, smax, dMaglim, L):\n",
    "    \"\"\"Compute the completeness of an observation\n",
    "\n",
    "    Args:\n",
    "        Cpdf (np.ndarray):\n",
    "            2D, normalized, joint probability histogram of s and dMag\n",
    "        sax (np.ndarray):\n",
    "            Projected separation axis of Cpdf (AU)\n",
    "        dMagax (np.ndarray):\n",
    "            dMag axis of Cpdf\n",
    "        smin (arraylike):\n",
    "            Minimum observable projected separation (projected IWA) (AU)\n",
    "        smax (arraylike):\n",
    "            Maximum observable projected separation (projected OWA) (AU)\n",
    "        dMaglim (arraylike):\n",
    "            Maximum observable Delta mag value\n",
    "        L (arraylike):\n",
    "            Stellar luminosity in solar luminosities\n",
    "\n",
    "    Returns:\n",
    "        arraylike:\n",
    "            Completeness values\n",
    "    \n",
    "    Notes:\n",
    "        All arraylike inputs must have the same dimensionalities (or be scalars)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Your code goes here\n",
    "\n",
    "    comp = \n",
    "    \n",
    "    return comp\n",
    "\n",
    "# if you get stuck: a reference implementation is available in SSWYieldModelingTutorial.calc_completeness\n",
    "\n",
    "# when you're done, test your function:\n",
    "calc_completeness(Cpdf, sax, dMagax, 0.075, 1, 25, 1.5)\n",
    "# the expected output is ~0.258"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb46b1-69b6-448a-bfa5-9db6432e8276",
   "metadata": {},
   "source": [
    "## The Impact of Stellar Luminosity\n",
    "\n",
    "We can now explore how changing the luminosity impacts completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddc6e4-a8f5-4620-8d67-9027a13e05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume a fixed star at 10 pc:\n",
    "d = 10 # parsecs\n",
    "IWA = 0.05 # arcseconds\n",
    "OWA = 0.25 # arcseconds\n",
    "smins = IWA*d\n",
    "smaxs = OWA*d\n",
    "dMaglim = 25\n",
    "\n",
    "# generate a logarithmically spaced array of luminosities\n",
    "Ls = np.logspace(np.log10(0.06), np.log10(30), 40)\n",
    "comps2 = SSWYieldModelingTutorial.calc_completeness(Cpdf, sax, dMagax, smins, smaxs, dMaglim, Ls)\n",
    "\n",
    "ylim = [20,45]\n",
    "dmags2 = dMaglim - 2.5 * np.log10(Ls)\n",
    "smins2 = smins/np.sqrt(Ls)\n",
    "smaxs2 = smaxs/np.sqrt(Ls)\n",
    "fig6, axs6 = plt.subplots(1, 2)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cs = axs6[0].contourf(\n",
    "        sax,\n",
    "        dMagax,\n",
    "        Cpdf,\n",
    "        locator=ticker.LogLocator(),\n",
    "    )\n",
    "axs6[0].set_xlabel(\"$s/\\sqrt{L}$ (AU)\")\n",
    "axs6[0].set_ylabel(\"$\\Delta$mag - 2.5$\\log_{10}(L)$\")\n",
    "pIWA2 = axs6[0].plot([smins2[0]] * 2, [ylim[0], dmags2[0]], \"k--\", label=\"Projected IWA\")[0]\n",
    "pOWA2 = axs6[0].plot([smaxs2[0]] * 2, [ylim[0], dmags2[0]], \"k-.\", label=\"Projected OWA\")[0]\n",
    "dmaglim2 = axs6[0].plot(\n",
    "    [smins2[0], smaxs2[0]], [dmags2[0]] * 2, \"k:\", label=\"$\\\\Delta$mag$_\\\\mathrm{lim}$\"\n",
    ")[0]\n",
    "axs6[0].legend(loc=1)\n",
    "axs6[0].set_ylim(ylim)\n",
    "fig6.suptitle(f\"$L = ${Ls[0] :.3f} $L_\\odot$\")\n",
    "\n",
    "compline2 = axs6[1].semilogx(Ls[0], comps2[0])[0]\n",
    "comppoint2 = axs6[1].scatter(Ls[0], comps2[0])\n",
    "axs6[1].set_xlim([np.min(Ls), np.max(Ls)])\n",
    "axs6[1].set_ylim([0, 1])\n",
    "axs6[1].set_xlabel(\"Star Luminosity ($L_\\odot$)\")\n",
    "axs6[1].set_ylabel(\"Completeness\")\n",
    "\n",
    "plt.subplots_adjust(top=0.925, left=0.075, right=0.975)\n",
    "\n",
    "\n",
    "def drawCompFrame2(j):\n",
    "    pIWA2.set_data([smins2[j]] * 2, [ylim[0], dmags2[j]])\n",
    "    pOWA2.set_data([smaxs2[j]] * 2, [ylim[0], dmags2[j]])\n",
    "    dmaglim2.set_data([smins2[j], smaxs2[j]], [dmags2[j]] * 2)\n",
    "    if smaxs2[j] > sax.max():\n",
    "        axs6[0].set_xlim([0, np.ceil(smaxs2[j]*10)/10])\n",
    "    else:\n",
    "        axs6[0].set_xlim([0,sax.max()])\n",
    "    fig6.suptitle(f\"$L = ${Ls[j] :.3f} $L_\\odot$\")\n",
    "    compline2.set_data(Ls[: j + 1], comps2[: j + 1])\n",
    "    comppoint2.set_offsets((Ls[j], comps2[j]))\n",
    "\n",
    "widgets.interact(drawCompFrame2, j=widgets.IntSlider(min=0, max=len(Ls)-1, step=1, value=0));\n",
    "# use slider to change the star luminosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cf607-7756-4c23-b8ff-c2a2b1270b21",
   "metadata": {},
   "source": [
    "Note that the effect of scaling stellar luminosity is a bit more complex than when changing the stellar distance, as the luminosity changes the bounds of the box we're integrating within in both dimensions. For low stellar luminosities, the habitable zone moves inwards, towards the star, making the requirements on IWA very challenging.  For a fixed IWA, as we're assuming here, eventually the full joint distribution moves outside of the bounding box (at somewhere around 0.06 solar luminosities). For the assumed fixed distance of 10 pc (and our IWA/OWA/limiting $\\Delta\\mathrm{mag}$) assumptions), we find a peak in the completeness at around 0.65 solar luminosities.  As we continue to increase the luminosity, the habitable zone keeps moving outwards (which makes for easier IWA requirements) but the planets also get fainter (due to the reciprocal orbital radius magnitude term in the $\\Delta\\mathrm{mag}$ equation), making instrumental limiting $\\Delta\\mathrm{mag}$ requirements more challenging. By the time we get to 30 solar luminosities (roughly an A1V star - think just a bit dimmer than Vega), the bounding box has fully moved *below* the joint density function and the completeness is once again zero.\n",
    "\n",
    "Finally, always remember that both the luminosity scaling and stellar distance scaling effects are happening at the same time!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394f17c-e95d-4f29-9a48-954a1e484497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
